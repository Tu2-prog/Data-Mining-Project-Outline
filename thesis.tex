% Do not change document class, margins, fonts, etc.
\documentclass[a4paper,oneside,bibliography=totoc]{scrbook}

% some useful packages (add more as needed)
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{algorithm} % you can modify the algorithm style to your liking
\counterwithin{algorithm}{chapter} % so that algorithms have chapter numbers as well
\usepackage{algorithmic}
\usepackage{csquotes}
\renewcommand{\algorithmiccomment}[1]{\hfill\textit{// #1}}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks,citecolor=Green]{hyperref} % you may change/remove the colors
\usepackage{lipsum} % you do not need this


% chicago citation style
\usepackage{natbib}
\usepackage{calc}
\bibliographystyle{chicagoa}
\setcitestyle{authoryear,round,semicolon,aysep={},yysep={,}} \let\cite\citep

% example enviroments (add more as needed)
\newtheorem{definition}{Definition} \newtheorem{proposition}{Proposition}


\begin{document}

\frontmatter \subject{Data Mining Project Outline HWS24} % change to appropriate type
\title{Gradient Descent Gururs - Predictive Modelling Train Delays}
\author{Raphael Ebner$^{2111615}$, Anh Tu Duong Nguyen$^{2115931}$, Adrian Scheibelhut$^{2110910}$,\\ Georgios Terzidis$^{2114215}$, Harrison Walker$^{2115335}$} \date{October 13, 2024}
\publishers{{\small Submitted to}\\
Data and Web Science Group\\
Prof.\ Dr.\ Hertling\\
University of Mannheim\\}

\maketitle
% none of the things below is needed, but you may add them if you feel that they
% are helpful for your work \listofalgorithms \listoffigures \listoftables
% \listtheorems{definition} \listtheorems{proposition}

% okay, start new numbering ... here is where it really starts

\mainmatter

\chapter{Introduction}
\label{ch:intro}

Railway systems are crucial for public transportation,
as maintaining punctual schedules is essential for operational efficiency and passenger satisfaction.
In recent years, delays have become a significant concern for Deutsche Bahn,
disrupting commuters and long-distance travellers.
This project aims to develop a predictive model that categorises train delays based on various factors,
providing detailed insights into their nature and severity.
This will create a more structured framework for delay prediction.

The analysis will use historical data from Deutsche Bahn, including location,
train type (e.g., RE, RB, S-Bahn), and external factors like weather and time of day.
The project applies scientific methodologies and data mining techniques to address a real-world transportation problem,
incorporating machine learning models aligned with state-of-the-art approaches.

From a business perspective, predicting delays could enable Deutsche Bahn to implement proactive strategies,
optimise resource allocation and scheduling,
and enhance customer satisfaction.
Passengers would benefit from more accurate information on expected delays, improving their journey planning.
Therefore, the project presents an academic challenge and the potential for meaningful business impact.


\chapter{Methodology}
\label{ch:methodology}
This chapter outlines the methodology that is pursued for our group project.
Section~\ref{sec:dataset} explains the overall process on compiling the data for our project.
Section~\ref{sec:data-mining-methodology} provides an overview
on how we want to tackle the problems we have stated in Chapter~\ref{ch:intro}.

\section{Data Collection Methodology}
\label{sec:dataset}

We will either use a dataset from Kaggle\footnote{https://www.kaggle.com/datasets/nokkyu/deutsche-bahn-db-delays}
or collect our data by crawling.
Although a dataset is available on Kaggle, it is rather small and only covers a week in July 2024
(08.07.2024 to 14.07.2024).
To enhance the quality and performance of our analysis,
we propose
gathering additional data from the same source using the Timetables API and the StaDa API from the DB API marketplace.
This approach allows us to collect more recent and extensive data while, if required,
maintaining consistency with the source used for the Kaggle dataset.
However, if crawling proves too challenging or time-consuming, we will use the existing Kaggle dataset.
The dataset will contain the following data:

\begin{itemize}
    \item Station
    \item Line
    \item Path
    \item Size of Station
    \item State
    \item City
    \item Postcode
    \item Planned Arrival
    \item Planned Departure
    \item Actual Arrival
    \item Actual Departure
    \item Announcements, i.e.\ construction on the track
\end{itemize}


\section{Data Mining Methodology}
\label{sec:data-mining-methodology}

Several pre-processing steps are required before beginning the main analysis.

Our pre-processing steps may include:
\begin{enumerate}
    \item Aggregating data from multiple sources into a single dataset (when required).
    \item Handling missing data, such as routes without end stations.
    \item Transforming categorical variables into numerical values.
    \item Binning the data based on factors such as delay duration, geographic regions, and station identifiers,
    to enable subsequent clustering.
    \item Detecting and removing outliers, such as train rides from less frequented regions,
    as there may be insufficient data points for meaningful comparisons.
\end{enumerate}

After pre-processing, we will explore the data to identify underlying trends and biases,
such as geographic patterns in train journeys.
We will use these insights to inform feature engineering for our models if we discover significant trends,
such as increased delays during peak hours.

We will focus on regression algorithms for delay prediction when working with the kaggle dataset.
Since most delays are less than six minutes, binning the data into multiple classes would result in overly narrow time intervals.
Therefore, we plan to use interpolating regression trees to provide reasonable predictions based on the intervals within the training dataset.

If we work with the aforementioned custom dataset, we will use multiclass classification, as it performs better with imbalanced data. % what do you mean by imbalanced data?
We plan to explore methods such as Decision Trees and Nearest Centroid classifiers for this purpose.

To ensure clarity and consistency, when comparing models to select the best one,
we will only compare regression models against other regression models and classification models against other classification models.
Cross-comparisons between regression and classification models will not be performed.

\chapter{Evaluation of the Model}
\label{ch:eval}

The delay prediction model will be evaluated by partitioning the dataset, with 20\% of the data reserved for testing.
This split is commonly regarded as a standard practice in data mining.
To prevent overfitting, we will apply 10-fold cross-validation to the remaining 80\% of the data.
This approach allows us to make better use of the training data while also facilitating hyperparameter optimisation.

For multiclass classification, the performance will primarily be measured using the F1 score,
as it balances precision and recall, which is particularly relevant when dealing with discrete classes.
Additionally, a confusion matrix will be used to provide insights into how well the model distinguishes between delay categories, such as short and medium delays.
We will also conduct a cost analysis to assess the impact of misclassifications, placing particular emphasis on high-impact errors.
For example, from the user's perspective,
incorrectly predicting a delay of 0–5 minutes when the actual delay is 30–35 minutes would be more detrimental than an error within smaller time intervals,
such as predicting a 5–10 minute delay.

If regression is used, we will evaluate the model with the R² score and Root Mean Squared Error (RMSE).
The R² score focuses on how much of the variance in the data is explained by the model, thus providing insight into its reliability.
In contrast, RMSE measures the average difference between the predicted and actual values,
offering a clear interpretation in the same units as the target variable.

\chapter{Expected Results}
\label{ch:expected_results}

The project aims to develop a model that accurately predicts train delays by both category and duration.
While perfect accuracy is not expected, the goal is to provide reliable predictions that can support decision-making in train scheduling.

The expected outcomes include uncovering patterns that associate delays with specific factors,
such as stations, times of day, and geographic regions.
For example, certain stations may emerge as bottlenecks, experiencing more frequent or prolonged delays.
Similarly, high-traffic regions may reveal delay trends.
Additionally, external factors, such as holidays or local events, could be linked to extended delays in particular areas.
Identifying these trends will contribute to a better understanding of the causes of train delays, ultimately improving scheduling and resource allocation.


\backmatter

\chapter{Declaration of honor}\label{ch:declaration-of-honor}
I hereby declare that I have written the enclosed Bachelor's, Master's,
seminar or project work without the help of third parties and without using any sources other than those listed and the aids listed in the table below,
and that I have marked the passages taken from the sources used as such, either literally or in terms of content.
This thesis has not yet been submitted to any examination authority in the same or a similar form.
I am aware that a false declaration will have legal consequences.

% Declare below which AI tools you used in the process of writing your work,
% including text, image, code, and data generation. If you used a tool for a
% purpose not included in the list yet, add it to the list.
\begin{center}
    \textbf{Declaration of Used AI Tools} \\[.3em]
    \begin{tabularx}{\textwidth}{lXlc}
        \toprule
        Tool        & Purpose                       & Where?
        & Useful? \\
        \midrule
        ChatGPT/GPT-4o     & Rephrasing and Grammar correction                  & Throughout                    & ++       \\
        Grammarly   & Grammar correction            & Throughout                    & ++       \\
        ChatGPT/GPT-4o     & Grammar correction               & Throughout     & +        \\
        \bottomrule
    \end{tabularx}
\end{center}
\vspace{2cm}
\noindent Signature\\
\noindent Mannheim, den 13.October.2024 \hfill

\end{document}
